[
    {
        "name": "Sensu Installation Package",
        "start": "February 2018",
        "end": "April 2018",
        "description": "We needed to take our Sensu monitoring platform from its proof of concept stage to a fully deployed monitoring solution. I created the installation package that installed and configured the monitoring agent on machines.",
        "challenges": "We had two methods of deploying the package: Opsware and Rundeck. Opsware accepted bash, python and powershell scripts while Rundeck accepted Ansible playbooks. Rundeck had cross-platform playbooks, and Opsware for windows was pretty safe with powershell 3. The hardest part was linux for Opsware. There were so many flavors of linux and versions of kernals. After I got major installation steps completed, I spent plenty of time tweaking the package to work perfectly on different linux flavors.",
        "stack": ["bash", "python", "powershell", "ansible"]
    },
    {
        "name": "Grafana CAPM Datasource",
        "start": "May 2018",
        "end": "May 2018",
        "description": "Our network team needed to view data that was collected from CA Performance Manager (CAPM), so two developers and I wrote a datasource that wrapped a CAPM api. This allowed the network team to view all of their existing data in a single pane within Grafana.",
        "challenges": "None of us knew anything about Grafana or CAPM. We spent the first few days researching and reverse engineering an obfuscated proof of concept example. After we started painting the picture, we quickly finished the project in a week.",
        "stack": ["grafana", "angular", "html", "css"]
    },
    {
        "name": "Grafana ServiceNow Datasource",
        "start": "August 2018",
        "end": "August 2018",
        "description": "Asset owners wanted to see if any open alerts/tickets were opened against their servers. They wanted to see all of this information within a single pane inside Grafana.",
        "challenges": "Wrapping the api was difficult because the documentation was poor. Eventually my team and I found the necessary endpoints and wrapped this project up quickly.",
        "stack": ["grafana", "angular", "html", "css"]
    },
    {
        "name": "Sensu Self-Updating Client",
        "start": "July 2018",
        "end": "September 2018",
        "description": "We wanted our monitoring agents to maintain and update themselves, so would not need to create a bunch of change tickets every time we had to roll out an update.",
        "challenges": "We had no guaranteed connection to the server besides RabbitMQ, our message bus. We came up with a solution to serialize data, send it through RabbitMQ, rebuild the data on the client and install the data. A major contributor of Sensu said that reloading the agent without root was impossible, but we managed to reload certain pieces of the client to mimic a reload initiated by root. The next challenging part was fixing bugs. Our standalone development environment only got us so far. Many bugs showed when we moved to a distributed environment. Needless to say, we fixed the bugs. To add more complexity, we had to migrate chef to new environment in the middle of project. ",
        "stack": ["ruby", "sensu", "rabbitmq"]
    },
    {
        "name": "Landon Dao Profile v1",
        "start": "November 2017",
        "end": "January 2018",
        "description": "Around the time I started looking for a new job, I realized I had no way of showing my capabilities with web development. I spent years researching modern design trends and UI/UX. I created a simple and clean website to showcase my portfolio.",
        "challenges": "I totally enjoyed the process. I would say the challenging part was actually finishing the website. I looked up methods to host a static website and came accross github pages. It was perfect for me!",
        "stack": ["javascript", "html", "css"]
    },
    {
        "name": "Landon Dao Profile v2",
        "start": "August 2018",
        "end": "August 2018",
        "description": "I always wanted to learn a modern JS framework. I like front end web development very much. Creating this website was my excuse to learn something new.",
        "challenges": "I enjoyed this project just like I enjoy everything I do outside of work. A slight challenge I came across was trying to load an image from a dynamic source.",
        "stack": ["react", "html", "css"],
        "link": "https://github.com/landondao1/v2"
    },
    {
        "name": "Sensu Event Management Handler v2",
        "start": "September 2018",
        "end": "September 2018",
        "description": "There was already a v1 of a sensu handler that took events that sensu generated and sent them to a data processing queue called Event Management which sent alerts to Service Now.",
        "challenges": "When I first saw the code, I noticed many functions were doing much more than the function name stated. Getters were setting fields and every variable was an instance variable regardless of scope. I refactored to code to be modular and plugable. Another issue was test cases. The repo previously had only a few test cases. I increased the number to 54 and covered every case, so any bad data would not break the handler.",
        "stack": ["sensu", "python"]
    },
    {
        "name": "Chef Migration",
        "start": "August 2018",
        "end": "October 2018",
        "description": "GE was getting rid of the Chef server that everyone used. We had a few weeks to migrate our cookbooks/data bags/policies elsewhere. We decided to spin up our own chef automate server and chef server.",
        "challenges": "Getting the servers to cooperate with LDAP took a while. I had all of my configurations correct. The problem was the base_dn I was given. It was all lowercase with a single character capitalized. I thought it was meant to be capitalized, so I struggled with the errors until I finally found someone who gave me the correct base_dn with all lowercase characters. The second problem was allowing clients to bootstrap without having to manually trust the server's certificate. After getting a signed certificate from a certificate authority, I put the certificate on the server and pointed nginx to use them. Our next problem occurred when we started spinning up new instances using our new chef server. All of the cookbooks were failing because they were outdated. To add complexity, GE github removed anonymous access which most of our cookbooks accessed github repos without authentication. We fixed all of the cookbooks and upgraded our self-managed redis cluster to an AWS managed elasticache redis cluster. Overall performance of the platform greatly increased.",
        "stack": ["aws", "chef", "nginx", "redis", "rabbitmq"]
    },
    {
        "name": "Sensu SNMP Traps",
        "start": "October 2018",
        "end": "November 2018",
        "description": "In order to consolidate the tech stack, we incorporated snmp traps into sensu. The goal was to be able to scale out the trap servers behind an nginx load balancer. We created a cookbook to provision a sensu client with an snmp trap receiver plugin, updated an existing nginx cookbook to allow a udp upstream and configured AWS NACL/Security Groups for our vpc, subnet and ec2 instances to allow inbound traffic on port 162. I really enjoyed this project because it allowed me to learn so much about networking.",
        "challenges": "We stood up the servers quickly, but the network firewall rules controlled by the network team denied us. To overcome this, we submitted change requests to open our ports. The second and main issue is forwarding the source ip address to the snmp traps. The nginx load balancer was sending its own ip address with the request to the snmp server. We ended up configuring ip transparency on the nginx servers and disabling the source/destination check on the elastic network interface.",
        "stack": ["aws", "chef", "nginx", "sensu"]
    },
    {
        "name": "Event Management API",
        "start": "December 2018",
        "end": "August 2019",
        "description": "Event Management is a system that clustered events together to reduce alarm noises. The api allowed users to post events, silence assets that events alert, and route event to different support groups.",
        "challenges": "I inherited this api in a state of confusion. The team previously running the api inherited it from another team that was disbanded. This project was difficult to develop locally, which made deployments very scary. The first thing I did was set up a local environment and spin up the tornado api on my machine. I started by fixing many bugs and inefficiencies. After everything seemed well, I worked on adding more functionality that allowed the system to perform more intelligently.",
        "stack": ["ec2", "kafka", "elasticache", "rds", "python", "tornado"]
    },
    {
        "name": "Event Management API v2",
        "start": "February 2019",
        "end": "Present",
        "description": "After stablizing Event Management, I realized that it would not be able to scale any further. The vpc we hosted the platform in ran out of ip addresses for the subnet making it impossible to horizontally scale our tornado api. In attempt to design a platform for the future, I decided to use a serverless (almost) model.",
        "challenges": "The easy part was redesigning the application code to be easier to read as well as operate more efficiently. On the contrary, my team and I faced many bugs deploying our api gateway and lambda in aws. When we deployed our api with cloudformation, everything seemed fine, but we kept getting an internal server error. After adding debug statements, we realized that our api gateway was linked to different lambda version, and we received an APP_SPEC error. We implemented a workaround that aws support provided and received an entirely different bug in aws. With these two bugs, we found a workaround that worked some of the time which was the best thing we had. AWS did not respond yet since April 2019. In addition to the deployment troubles, tracking down all of the api users and getting them to migrate to the new api took two months.",
        "stack": ["gateway", "lambda", "ec2", "msk", "elasticache", "rds", "python"]
    },
    {
        "name": "MyNotify Rewrite",
        "start": "July 2019",
        "end": "July 2019",
        "description": "MyNotify was a 5000 line main method java application that was referred to as the worst java \"script\" that we have ever seen. It processed events from a directory before sending the results to Event Management. No one wanted to touch the code because it was really intimidating looking at a poorly coded application. There were try-catches around every other line of code (for no reason), none of the connections were being closed, and the application kept locking up. Any time a change was made to the application or the credentials changed in the properties file, we manually had to push the changes out to ~30 servers one by one. I hated the idea that this was wasting so much of my team's time, so I redesigned the application and added a way to remotely push the artifact and new secrets via chef. I spent four days rewriting the code, four days creating a chef cookbook for the application, and one day on testing and deploying.",
        "challenges": "Reading the code was terrible. In my entire career, I have never seen such lack of structure nor lack of knowledge in programming put into such a critical application. After sucessfully copying over all of the original functionality, I had troubles with adding chef on Windows Server 2003. We had 15 windows servers, and they were all configured entirely different. Majority of my time testing and deploying was trying to get the chef clients to check in. Since these servers were across networks, I had a difficult time configuring the servers to be able to connect back to the chef server. On the other hand, the 12 linux servers took 10 minutes of my time.",
        "stack": ["chef", "java"]
    },
    {
        "name": "BGP Alert Ticketing",
        "start": "July 2019",
        "end": "July 2019",
        "description": "In Event Management we were only able to create incidents in Service Now if the alert mapped to a valid asset in the system. The border gateway protocol (BGP) alerts were triggered with one of many ip addreses for an asset, but Service Now only kept track of one ip address per asset. I added a component that allowed the system to do a reverse lookup on the ip address to get the hostname for Service Now.",
        "challenges": "The actual solution took two days to stand up the dns api and add a modular component that resolved the ip address to a Service Now asset. The difficulty of this project was the miscommunication and language barrier between other network engineers. I tried four different solutions before the right solution was accepted. Other challenges with this project was that I was unable to reach the dns server from AWS, so I had to put an api that got the hostname from inside GE network.",
        "stack": ["python", "nodejs", "express", "chef"]
    },
    {
        "name": "Ticket Relationship Correlation",
        "start": "July 2019",
        "end": "Present",
        "description": "In an effort to reduce the operational noise, I wanted to correlate tickets created on assets with the asset's upstream relationships. If a server went down, for example, I wanted to create a ticket for the router that it was connected to. This played an important role since widespread network outages at GE meant that more than 1000 servers could generate tickets in Service Now, while only one ticket on the upstream router would have been needed. It saved operations engineers from having to waste time combing through the massive dump of incidents and closing them out as well as saving money from not having to hire more operations engineers as the workload decreased. My choice to use a graph database was also intended to be used in the future for role based access control to manage the front end for Event Management.",
        "challenges": "The most difficult thing about this project is learning gremlin in python. It is very hard to find documentation on the language, so I ended up reading the source code to learn how to use the module.",
        "stack": ["python", "gremlin", "neptune"]
    }
]